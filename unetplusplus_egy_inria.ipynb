{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOem/C1jyF4pR9VzNLaX81G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hJqpOXQ-2UdO","executionInfo":{"status":"ok","timestamp":1700840927814,"user_tz":-180,"elapsed":26785,"user":{"displayName":"igor obed","userId":"12524563447445034049"}},"outputId":"2b283f31-eec8-49bd-d57e-c7aa50100d62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Collecting opencv-python\n","  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.23.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.3)\n","Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n","Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n","Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.8.1.78)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (23.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n","Installing collected packages: opencv-python\n","  Attempting uninstall: opencv-python\n","    Found existing installation: opencv-python 4.8.0.76\n","    Uninstalling opencv-python-4.8.0.76:\n","      Successfully uninstalled opencv-python-4.8.0.76\n","Successfully installed opencv-python-4.8.1.78\n","Collecting segmentation-models-pytorch\n","  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.16.0+cu118)\n","Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.2 (from segmentation-models-pytorch)\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.0+cu118)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.19.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=8f4b6a39a39f75656ce4add8f5321585068d4cb9f68723f07c599fda94c9f8ec\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=1201d19f7a8212b84962670abe2a82135c494be64b3da65810de860661860ea2\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n"]}],"source":["!pip install -U albumentations opencv-python\n","!pip install segmentation-models-pytorch"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEqANg5E36lK","executionInfo":{"status":"ok","timestamp":1700840944422,"user_tz":-180,"elapsed":16612,"user":{"displayName":"igor obed","userId":"12524563447445034049"}},"outputId":"852258df-270b-45a1-db6f-7b6e874358f1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["import tarfile\n","import pandas as pd\n","import zipfile\n","from zipfile import ZipFile\n","import os\n","from random import sample\n","from os import listdir\n","import cv2\n","import numpy as np\n","from tqdm import tqdm\n","import time\n","from tempfile import TemporaryDirectory\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","import segmentation_models_pytorch as smp\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.optim import lr_scheduler\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"g9Bq5HTo4WAb","executionInfo":{"status":"ok","timestamp":1700840959359,"user_tz":-180,"elapsed":14940,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"3Po9pmtD4y9O","executionInfo":{"status":"ok","timestamp":1700840961024,"user_tz":-180,"elapsed":436,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/skoltech_hack/data/dataset_egy_inria.zip .\n","\n","file_name = \"dataset_egy_inria.zip\"\n","with ZipFile(file_name, 'r') as zip:\n","\n","    # extracting all the files\n","    print('Extracting all the files now...')\n","    zip.extractall()\n","    print('Done!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXl9ZxkZ42Tt","executionInfo":{"status":"ok","timestamp":1700840988709,"user_tz":-180,"elapsed":27686,"user":{"displayName":"igor obed","userId":"12524563447445034049"}},"outputId":"d69bc120-d358-4491-c850-d1113cff48d2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting all the files now...\n","Done!\n"]}]},{"cell_type":"code","source":["!ls dataset_egy_inria/inria"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qsnnlRKa5Kfo","executionInfo":{"status":"ok","timestamp":1700840988710,"user_tz":-180,"elapsed":17,"user":{"displayName":"igor obed","userId":"12524563447445034049"}},"outputId":"17289a75-d857-418a-92be-71ad23d6b605"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["256\n"]}]},{"cell_type":"code","source":["images_1_dir = \"./dataset_egy_inria/EGY_BCD/256/images/\"\n","masks_1_dir = \"./dataset_egy_inria/EGY_BCD/256/masks/\"\n","names_1 = listdir(images_1_dir)\n","# masks = listdir(\"./EGY_BCD/label\")\n","\n","data_df_1 = pd.DataFrame(\n","    {\n","        \"img_path\": [images_1_dir + name for name in names_1],\n","        \"mask_path\": [masks_1_dir + name for name in names_1]\n","    }\n",")"],"metadata":{"id":"0EtXjYYT5Wv4","executionInfo":{"status":"ok","timestamp":1700840988710,"user_tz":-180,"elapsed":13,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["images_2_dir = \"./dataset_egy_inria/inria/256/images/\"\n","masks_2_dir = \"./dataset_egy_inria/inria/256/masks/\"\n","names_2 = listdir(images_2_dir)\n","# masks = listdir(\"./EGY_BCD/label\")\n","\n","data_df_2 = pd.DataFrame(\n","    {\n","        \"img_path\": [images_2_dir + name for name in names_2],\n","        \"mask_path\": [masks_2_dir + name for name in names_2]\n","    }\n",")"],"metadata":{"id":"HrEuW4wB59ym","executionInfo":{"status":"ok","timestamp":1700840988710,"user_tz":-180,"elapsed":12,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["data_df = pd.concat([data_df_1, data_df_2])"],"metadata":{"id":"VFcM_G_W5_jP","executionInfo":{"status":"ok","timestamp":1700840988710,"user_tz":-180,"elapsed":12,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["data_df.sample(4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"_HFEunkM6srs","executionInfo":{"status":"ok","timestamp":1700840988710,"user_tz":-180,"elapsed":11,"user":{"displayName":"igor obed","userId":"12524563447445034049"}},"outputId":"4919d52a-8f20-4585-bc5e-f8736bb6d2e1"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               img_path  \\\n","157   ./dataset_egy_inria/inria/256/images/11_chicag...   \n","2823  ./dataset_egy_inria/inria/256/images/4_tyrol-w...   \n","2415  ./dataset_egy_inria/inria/256/images/30_austin...   \n","6228  ./dataset_egy_inria/inria/256/images/5_chicago...   \n","\n","                                              mask_path  \n","157   ./dataset_egy_inria/inria/256/masks/11_chicago...  \n","2823  ./dataset_egy_inria/inria/256/masks/4_tyrol-w1...  \n","2415  ./dataset_egy_inria/inria/256/masks/30_austin3...  \n","6228  ./dataset_egy_inria/inria/256/masks/5_chicago2...  "],"text/html":["\n","  <div id=\"df-a07933c5-47b3-4ac8-a882-11e1446daffa\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_path</th>\n","      <th>mask_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>157</th>\n","      <td>./dataset_egy_inria/inria/256/images/11_chicag...</td>\n","      <td>./dataset_egy_inria/inria/256/masks/11_chicago...</td>\n","    </tr>\n","    <tr>\n","      <th>2823</th>\n","      <td>./dataset_egy_inria/inria/256/images/4_tyrol-w...</td>\n","      <td>./dataset_egy_inria/inria/256/masks/4_tyrol-w1...</td>\n","    </tr>\n","    <tr>\n","      <th>2415</th>\n","      <td>./dataset_egy_inria/inria/256/images/30_austin...</td>\n","      <td>./dataset_egy_inria/inria/256/masks/30_austin3...</td>\n","    </tr>\n","    <tr>\n","      <th>6228</th>\n","      <td>./dataset_egy_inria/inria/256/images/5_chicago...</td>\n","      <td>./dataset_egy_inria/inria/256/masks/5_chicago2...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a07933c5-47b3-4ac8-a882-11e1446daffa')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a07933c5-47b3-4ac8-a882-11e1446daffa button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a07933c5-47b3-4ac8-a882-11e1446daffa');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a538a4b6-5afa-404e-b099-82e1b850a280\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a538a4b6-5afa-404e-b099-82e1b850a280')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a538a4b6-5afa-404e-b099-82e1b850a280 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["train_df, val_df = train_test_split(data_df, test_size=0.2)"],"metadata":{"id":"D1yrRkQS6wfL","executionInfo":{"status":"ok","timestamp":1700840988710,"user_tz":-180,"elapsed":9,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["transform_train = A.Compose([\n","\n","    A.RandomRotate90(p=1),\n","    A.Normalize(),\n","    A.Resize(256, 256),\n","    ToTensorV2()\n","])\n","\n","transform_val = A.Compose([\n","    A.Normalize(),\n","    A.Resize(256, 256),\n","    ToTensorV2()\n","])"],"metadata":{"id":"qXXtqIg1--tc","executionInfo":{"status":"ok","timestamp":1700840988710,"user_tz":-180,"elapsed":9,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class BuildingDataset(Dataset):\n","  def __init__(self, df, transforms=None):\n","    self.df = df\n","    self.transforms = transforms\n","\n","  def __getitem__(self, idx):\n","    img_path = self.df.iloc[idx].img_path\n","    mask_path = self.df.iloc[idx].mask_path\n","\n","    img = cv2.imread(img_path)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    mask = cv2.imread(mask_path)\n","    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n","    mask = np.float32(mask / 255)\n","\n","    if self.transforms:\n","      aug = self.transforms(image=img, mask=mask)\n","      img = aug[\"image\"]\n","      mask = aug[\"mask\"]\n","\n","    return img, mask\n","\n","  def __len__(self):\n","    return len(self.df)"],"metadata":{"id":"1_e9YODA_EHQ","executionInfo":{"status":"ok","timestamp":1700840988710,"user_tz":-180,"elapsed":8,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["train_dataset = BuildingDataset(train_df, transform_train)\n","val_dataset = BuildingDataset(val_df, transform_val)\n","\n","image_datasets = {\n","    \"train\": train_dataset,\n","    \"val\": val_dataset,\n","}"],"metadata":{"id":"g8rE_Zt7_Hby","executionInfo":{"status":"ok","timestamp":1700840988711,"user_tz":-180,"elapsed":9,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["dataloaders = {\n","    data_type: DataLoader(\n","        image_datasets[data_type],\n","        batch_size=16,\n","        shuffle=True\n","        )\n","    for data_type in [\"train\", \"val\"]\n","}\n","\n","dataset_sizes = {\n","    data_type: len(image_datasets[data_type]) for data_type in ['train', 'val']\n","    }"],"metadata":{"id":"P3pdhS2Z_KCB","executionInfo":{"status":"ok","timestamp":1700840988711,"user_tz":-180,"elapsed":8,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def train(model, criterion, optimizer, scheduler=None, num_epochs=5, save_path=\"./best\"):\n","    since = time.time()\n","\n","    best_model_params_path = save_path\n","\n","    torch.save(model.state_dict(), best_model_params_path)\n","    best_iou = 0.0\n","    best_f1 = 0.0\n","    best_loss = np.inf\n","\n","    train_loss_lst = []\n","    val_loss_lst = []\n","    metric_f1_lst = []\n","    metric_iou_lst = []\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","\n","        for phase in [\"train\", \"val\"]:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_iou = 0\n","            running_f1 = 0\n","\n","            for inputs, labels in tqdm(dataloaders[phase]):\n","                inputs = inputs.to(device)\n","                inputs = inputs.float()\n","                labels = labels.to(device)\n","\n","                # labels = torch.permute(labels, (0, 3, 1, 2))\n","                # inputs = torch.permute(inputs, (0, 3, 1, 2))\n","                labels = labels[:, np.newaxis, :, :]\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    # print()\n","                    # print(f\"outputs: {outputs.shape}\")\n","                    # print(f\"labels: {labels.shape}\")\n","                    loss = criterion(outputs, labels)\n","                    # print(f\"loss: {loss.item()}\")\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                # print()\n","                # print(f\"inputs.size(0): {inputs.size(0)}\")\n","                # print(f\"loss: {loss.item()}\")\n","                running_loss += loss.item() * inputs.size(0)\n","                # print(f\"loss.item() * inputs.size(0): {loss.item() * inputs.size(0)}\")\n","\n","                if phase == \"val\":\n","                    y_pred = F.sigmoid(outputs)\n","\n","                    # val_iou = iou_coef(labels, y_pred).cpu().detach().numpy()\n","                    tp, fp, fn, tn = smp.metrics.get_stats(y_pred, labels.long(), mode=\"binary\", threshold=0.5)\n","                    val_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\").item()\n","                    val_f1 = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\").item()\n","                    running_iou += val_iou\n","                    running_f1 += val_f1\n","\n","            if phase == 'train' and (not (scheduler is None)):\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","\n","            if phase == \"val\":\n","                epoch_iou = running_iou / len(dataloaders[phase])\n","                print(f'{phase} IOU: {epoch_iou:.4f}')\n","                epoch_f1 = running_f1 / len(dataloaders[phase])\n","                print(f'{phase} F1: {epoch_f1:.4f}')\n","                metric_iou_lst.append(epoch_iou)\n","                metric_f1_lst.append(epoch_f1)\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f}')\n","            if phase == \"train\":\n","              train_loss_lst.append(epoch_loss)\n","            elif phase == \"val\":\n","              val_loss_lst.append(epoch_loss)\n","\n","            # deep copy the model\n","            if phase == 'val':\n","                if epoch_iou > best_iou:\n","                    best_iou = epoch_iou\n","                if epoch_f1 > best_f1:\n","                    best_f1 = epoch_f1\n","\n","            if phase == \"val\" and epoch_loss < best_loss:\n","                torch.save(model.state_dict(), best_model_params_path)\n","                torch.save(model.state_dict(), \"/content/drive/MyDrive/best.pt\")\n","                best_loss = epoch_loss\n","\n","\n","\n","    time_elapsed = time.time() - since\n","    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val loss: {best_loss:4f}')\n","    print(f'Best val IOU: {best_iou:4f}')\n","    print(f'Best val F1: {best_f1:4f}')\n","\n","    # load best model weights\n","    model.load_state_dict(torch.load(best_model_params_path))\n","    return model, {\n","        \"train_loss\": train_loss_lst,\n","        \"val_loss\": val_loss_lst,\n","        \"metric_f1\": metric_f1_lst,\n","        \"metric_iou\": metric_iou_lst\n","    }"],"metadata":{"id":"8IMXxkaZADMP","executionInfo":{"status":"ok","timestamp":1700841860331,"user_tz":-180,"elapsed":3827,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["model = smp.UnetPlusPlus()\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gy4eKaz6AIjd","executionInfo":{"status":"ok","timestamp":1700841861346,"user_tz":-180,"elapsed":626,"user":{"displayName":"igor obed","userId":"12524563447445034049"}},"outputId":"8a64639a-94d9-47b0-d019-f39bc9939fc6"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["UnetPlusPlus(\n","  (encoder): ResNetEncoder(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (decoder): UnetPlusPlusDecoder(\n","    (center): Identity()\n","    (blocks): ModuleDict(\n","      (x_0_0): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_0_1): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_1_1): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_0_2): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_1_2): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_2_2): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_0_3): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_1_3): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_2_3): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_3_3): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","      (x_0_4): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention1): Attention(\n","          (attention): Identity()\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (attention2): Attention(\n","          (attention): Identity()\n","        )\n","      )\n","    )\n","  )\n","  (segmentation_head): SegmentationHead(\n","    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): Identity()\n","    (2): Activation(\n","      (activation): Identity()\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["criterion = smp.losses.DiceLoss(mode=\"binary\")\n","optimizer = optim.AdamW(model.parameters())\n","\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"],"metadata":{"id":"kIp-0lYwAt5F","executionInfo":{"status":"ok","timestamp":1700841862806,"user_tz":-180,"elapsed":2,"user":{"displayName":"igor obed","userId":"12524563447445034049"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["res_model, proc_dict = train(model, criterion, optimizer, num_epochs=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"j1iIET99A188","executionInfo":{"status":"error","timestamp":1700846084296,"user_tz":-180,"elapsed":4219475,"user":{"displayName":"igor obed","userId":"12524563447445034049"}},"outputId":"593aad5c-a3b6-4033-ca08-bbab4534108a"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:33<00:00,  2.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.3504\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:22<00:00,  4.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.5659\n","val F1: 0.7216\n","val Loss: 0.2798\n","Epoch 1/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:34<00:00,  2.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2891\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.5553\n","val F1: 0.7119\n","val Loss: 0.2892\n","Epoch 2/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2742\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6019\n","val F1: 0.7498\n","val Loss: 0.2504\n","Epoch 3/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2608\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.5961\n","val F1: 0.7455\n","val Loss: 0.2545\n","Epoch 4/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2514\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6230\n","val F1: 0.7667\n","val Loss: 0.2336\n","Epoch 5/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:33<00:00,  2.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2510\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6140\n","val F1: 0.7588\n","val Loss: 0.2415\n","Epoch 6/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2404\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6297\n","val F1: 0.7717\n","val Loss: 0.2285\n","Epoch 7/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2339\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:20<00:00,  5.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6256\n","val F1: 0.7683\n","val Loss: 0.2322\n","Epoch 8/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2327\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6230\n","val F1: 0.7665\n","val Loss: 0.2340\n","Epoch 9/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2281\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6203\n","val F1: 0.7644\n","val Loss: 0.2358\n","Epoch 10/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2225\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:20<00:00,  5.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6461\n","val F1: 0.7838\n","val Loss: 0.2167\n","Epoch 11/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2258\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6485\n","val F1: 0.7857\n","val Loss: 0.2142\n","Epoch 12/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2168\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6432\n","val F1: 0.7816\n","val Loss: 0.2181\n","Epoch 13/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2208\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:20<00:00,  5.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6395\n","val F1: 0.7790\n","val Loss: 0.2213\n","Epoch 14/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2161\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6546\n","val F1: 0.7903\n","val Loss: 0.2098\n","Epoch 15/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2081\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6578\n","val F1: 0.7923\n","val Loss: 0.2080\n","Epoch 16/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:32<00:00,  2.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2096\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:20<00:00,  5.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6425\n","val F1: 0.7811\n","val Loss: 0.2193\n","Epoch 17/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 434/434 [03:31<00:00,  2.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.2101\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 109/109 [00:21<00:00,  5.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val IOU: 0.6405\n","val F1: 0.7796\n","val Loss: 0.2203\n","Epoch 18/49\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["  8%|▊         | 34/434 [00:17<03:20,  1.99it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-d5e14cf67ab0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-36-f35f5c9ff1bd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;31m# print(f\"inputs.size(0): {inputs.size(0)}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# print(f\"loss: {loss.item()}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0;31m# print(f\"loss.item() * inputs.size(0): {loss.item() * inputs.size(0)}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"nGXSrTKQA6DD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9FU3DdiCTMsM"},"execution_count":null,"outputs":[]}]}