{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26080,"status":"ok","timestamp":1700884342885,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"lJn6vtQ55q3s","outputId":"5e2fe1b3-8072-496d-f037-a46754348efa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Collecting opencv-python\n","  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.23.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.3)\n","Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n","Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n","Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.8.1.78)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (23.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n","Installing collected packages: opencv-python\n","  Attempting uninstall: opencv-python\n","    Found existing installation: opencv-python 4.8.0.76\n","    Uninstalling opencv-python-4.8.0.76:\n","      Successfully uninstalled opencv-python-4.8.0.76\n","Successfully installed opencv-python-4.8.1.78\n","Collecting segmentation-models-pytorch\n","  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.16.0+cu118)\n","Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.2 (from segmentation-models-pytorch)\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.0+cu118)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.19.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=1955afce53e56900fc88dd0a8a6d4875078d71bbc79fda600609795f6a4ec954\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=7a0edbaf0b3193d90c67a0daadb045340d92c10af7eeb8c374e173bd041ff4df\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n"]}],"source":["!pip install -U albumentations opencv-python\n","!pip install segmentation-models-pytorch"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":13692,"status":"ok","timestamp":1700884356575,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"JpRR525pw_D1"},"outputs":[],"source":["import math\n","from copy import deepcopy\n","\n","import albumentations as A\n","import cv2\n","import numpy as np\n","import segmentation_models_pytorch as smp\n","import torch\n","import torch.nn.functional as F\n","from albumentations.pytorch.transforms import ToTensorV2\n","import time\n","\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1700884356576,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"_SNT46BC9Cwn"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22233,"status":"ok","timestamp":1700884378798,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"SuzfezPp5Hc4","outputId":"653db5c1-d9d1-4e1f-e905-1da641098ee5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":490,"status":"ok","timestamp":1700884389082,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"hvTEx8a754qg"},"outputs":[],"source":["def get_model(path, devices, type=\"unet\"):\n","    try:\n","        if type == \"unet\":\n","            model = smp.UnetPlusPlus()\n","        elif type == \"fpn\":\n","            model = smp.FPN()\n","        model.load_state_dict(\n","            torch.load(path, map_location=torch.device('cpu')))\n","        model.eval()\n","        dev = torch.device(devices if torch.cuda.is_available() else \"cpu\")\n","        model.to(dev)\n","        return model\n","    except Exception as error:\n","        print(error)\n","        return 1\n","\n","\n","def get_image(image_path):\n","    try:\n","        img = cv2.imread(image_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        (h, w) = (img.shape[0], img.shape[1])\n","        return img, h, w\n","    except Exception as error:\n","        print(error)\n","        return 2\n","\n","\n","def getDelta(dim, slidwinDim):\n","    count = math.ceil(dim / slidwinDim)\n","    return count\n","\n","\n","def get_tiles_overlap(inputImage, input_shape, overlap):\n","    splitted = []\n","\n","    Nx = getDelta(inputImage.shape[1], overlap)\n","    Ny = getDelta(inputImage.shape[0], overlap)\n","\n","    for i in range(Ny):\n","        for j in range(Nx):\n","            x_start = overlap * j\n","            y_start = overlap * i\n","\n","            x_end = x_start + input_shape\n","            y_end = y_start + input_shape\n","\n","            sub_img = inputImage[max(0, y_start): min(y_end, inputImage.shape[0]),\n","                      max(0, x_start):min(x_end, inputImage.shape[1]), :]\n","\n","            if x_start < 0:\n","                x_crop = np.hstack((np.zeros((sub_img.shape[0], abs(x_start), 3), dtype=np.uint8), sub_img))\n","            else:\n","                x_crop = deepcopy(sub_img)\n","            if x_end > inputImage.shape[1]:\n","                x_crop = np.hstack(\n","                    (sub_img, np.zeros((sub_img.shape[0], abs(input_shape - sub_img.shape[1]), 3),\n","                                       dtype=np.uint8)))\n","            if y_start < 0:\n","                y_crop = np.vstack((np.zeros((abs(y_start), x_crop.shape[1], 3), dtype=np.uint8), x_crop))\n","            else:\n","                y_crop = deepcopy(x_crop)\n","            if y_end > inputImage.shape[0]:\n","                y_crop = np.vstack((x_crop, np.zeros((input_shape - sub_img.shape[0], x_crop.shape[1], 3),\n","                                                     dtype=np.uint8)))\n","            splitted.append(y_crop)\n","\n","    return np.array(splitted, dtype=np.uint8), Nx, Ny\n","\n","\n","def get_transforms(input_shape):\n","    transforms = A.Compose([\n","        A.Normalize(),\n","        A.Resize(input_shape, input_shape),\n","        ToTensorV2()\n","    ])\n","    return transforms\n","\n","\n","def predict(model_lst, curr_img, transforms, threshold=0.5, device=\"cpu\"):\n","    # aug = transforms(image=curr_img)\n","    # proc_img = aug[\"image\"]\n","    # proc_img = proc_img[np.newaxis, :, :, :].float()\n","    # forward_res = model(proc_img)\n","    # res_mask = (F.sigmoid(forward_res) > threshold).int().detach().cpu().numpy()[0, 0]\n","    aug = transforms(image=curr_img)\n","    proc_img = aug[\"image\"]\n","\n","    proc_img = proc_img[np.newaxis, :, :, :].float()\n","    forward_res_lst = []\n","    for model in model_lst:\n","        prob = F.sigmoid(model(proc_img.to(device))).detach().cpu().numpy()[0, 0]\n","        forward_res_lst.append(prob)\n","    res_mask = np.zeros((forward_res_lst[0].shape))\n","    for prob_res in forward_res_lst:\n","        res_mask += prob_res\n","    res_mask /= len(model_lst)\n","    res_mask = (res_mask > threshold).astype(np.uint8)\n","    return res_mask\n","\n","\n","def create_kernel(M, std):\n","    n = torch.arange(0, M) - (M - 1.0) / 2.0\n","    sig2 = 2 * std * std\n","    w = torch.exp(-n ** 2 / sig2)\n","    gkern2d = torch.outer(w, w)\n","    return gkern2d.numpy()\n","\n","\n","def merge_tiles_with_smooth(splitted, kernel, h, w, overlap, shape_tile, Nx, Ny):\n","    rec_1 = np.zeros((h + shape_tile, w + shape_tile), dtype=np.float16)\n","    rec_2 = np.zeros((h + shape_tile, w + shape_tile), dtype=np.float16)\n","    rec_3 = np.zeros((h + shape_tile, w + shape_tile), dtype=np.float16)\n","    rec_4 = np.zeros((h + shape_tile, w + shape_tile), dtype=np.float16)\n","\n","    w_1 = np.zeros((h + shape_tile, w + shape_tile), dtype=np.float16)\n","    w_2 = np.zeros((h + shape_tile, w + shape_tile), dtype=np.float16)\n","    w_3 = np.zeros((h + shape_tile, w + shape_tile), dtype=np.float16)\n","    w_4 = np.zeros((h + shape_tile, w + shape_tile), dtype=np.float16)\n","\n","    for i in range(Ny):\n","        for j in range(Nx):\n","            n = (i) * Nx + (j)\n","            x_start = overlap * j\n","            y_start = overlap * i\n","\n","            x_end = x_start + shape_tile  # - delta\n","            y_end = y_start + shape_tile  # - delta\n","\n","            sub_img = splitted[n]\n","            if i % 2 == 0 and j % 2 == 0:\n","                rec_1[y_start:y_end, x_start:x_end] = sub_img * kernel\n","                w_1[y_start:y_end, x_start:x_end] = kernel\n","\n","            if i % 2 == 0 and j % 2 != 0:\n","                rec_2[y_start:y_end, x_start:x_end] = sub_img * kernel\n","                w_2[y_start:y_end, x_start:x_end] = kernel\n","            elif i % 2 != 0 and j % 2 == 0:\n","                rec_3[y_start:y_end, x_start:x_end] = sub_img * kernel\n","                w_3[y_start:y_end, x_start:x_end] = kernel\n","            elif i % 2 != 0 and j % 2 != 0:\n","                rec_4[y_start:y_end, x_start:x_end] = sub_img * kernel\n","                w_4[y_start:y_end, x_start:x_end] = kernel\n","    np.seterr(invalid='ignore')\n","    return np.true_divide((rec_1 + rec_2 + rec_3 + rec_4), (w_1 + w_2 + w_3 + w_4), dtype=np.float16)\n","\n","\n","def save_image(mask, path_save):\n","    try:\n","        cv2.imwrite(path_save, mask)\n","        return 0\n","    except Exception as error:\n","        print(error)\n","        return 3"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3581,"status":"ok","timestamp":1700884456740,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"4CQupCxw8oDd"},"outputs":[],"source":["input_shape = 256\n","overlap = input_shape // 2\n","\n","model_1 = get_model(\"/content/drive/MyDrive/skoltech_hack/data/val/fpn_isogd.pt\", device, type=\"fpn\")\n","model_2 = get_model(\"/content/drive/MyDrive/skoltech_hack/data/val/fpn_skoltech.pt\", device, type=\"fpn\")\n","model_3 = get_model(\"/content/drive/MyDrive/skoltech_hack/data/val/unetpp_resnet_skolkovo.pt\", device, type=\"unet\")\n","model_4 = get_model(\"/content/drive/MyDrive/skoltech_hack/data/val/unet_resnet_isogd.pt\", device, type=\"unet\")\n","\n","model_lst = [model_1, model_2, model_3, model_4]"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":416,"status":"ok","timestamp":1700884460062,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"i6f1hp0s_7fF"},"outputs":[],"source":["def run(model_lst, image_path, path_save, device, threshold=0.5):\n","    try:\n","\n","        input_shape = 256\n","        overlap = input_shape // 2\n","        array_image, h, w = get_image(image_path)\n","        tiles, Nx, Ny = get_tiles_overlap(array_image, input_shape, overlap)\n","        transforms = get_transforms(input_shape)\n","        y_pred = []\n","\n","        for tile in tqdm(tiles):\n","            pred = predict(model_lst, tile, transforms, device=device, threshold=threshold)\n","            y_pred.append(pred)\n","\n","        kernel = create_kernel(input_shape, 48)\n","        mask_pred = merge_tiles_with_smooth(y_pred, kernel, h, w, overlap, input_shape, Nx, Ny)\n","        mask_pred_true_shape = mask_pred[:array_image.shape[0], :array_image.shape[1]]\n","        stat_save = save_image(mask_pred_true_shape, path_save)\n","        return stat_save\n","    except Exception as error:\n","        print(error)\n","        return 4"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58874,"status":"ok","timestamp":1700884882458,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"47Azkf63ARCH","outputId":"10a8686a-b63a-493d-d079-64bbf3a7d2e4"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1085/1085 [00:51<00:00, 21.07it/s]\n"]},{"data":{"text/plain":["0"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["run(model_lst, \"/content/drive/MyDrive/skoltech_hack/data/val/train_image_013.png\", \"mask_013_4.png\", device)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":438,"status":"ok","timestamp":1700885232294,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"T3stQFlrEGx8"},"outputs":[],"source":["mask_1 = cv2.imread(\"mask_001_4.png\")"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1340,"status":"ok","timestamp":1700885235427,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"q2NS8Ex-GuUt","outputId":"cea58cbf-55bf-4b01-8036-ef5edabd1697"},"outputs":[{"data":{"text/plain":["array([0, 1], dtype=uint8)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["np.unique(mask_1)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700885235428,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"SoLMhlNPpgGw","outputId":"cbc78f20-9cca-4c96-a26b-12d6fb857b00"},"outputs":[{"data":{"text/plain":["3480834"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["np.sum(mask_1)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700885236132,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"5BXIK2UkGxl4","outputId":"505188e3-ee0f-4ec1-bc99-cba8d757a239"},"outputs":[{"data":{"text/plain":["(3824, 5973, 3)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["mask_1.shape"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":570,"status":"ok","timestamp":1700885240605,"user":{"displayName":"igor obed","userId":"12524563447445034049"},"user_tz":-180},"id":"ApuGM1o0GzxK","outputId":"8213f71d-cc53-4fb7-bd67-8001bfc68fef"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["mask_1 *= 255\n","cv2.imwrite(\"mask_001_255_4.png\", mask_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vjtc-H4ZHCFZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNUpAC5HKYY7EHSU47miEwA","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
